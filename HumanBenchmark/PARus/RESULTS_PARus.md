# PARus

train: 400 examples

dev: 100 examples

test: 500 examples


## HUMAN benchmark evaluation

3 overlap

Results for all examples:

```
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       249
           1       0.98      0.98      0.98       251

    accuracy                           0.98       500
   macro avg       0.98      0.98      0.98       500
weighted avg       0.98      0.98      0.98       500
```

Accuracy - 0.982


All tolokers don't make significant errors.

Only one of them 30% errors
Others less or not at all.
